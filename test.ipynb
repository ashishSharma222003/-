{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.bridge.pydantic import BaseModel, Field\n",
    "from llama_index.core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackInfo(BaseModel):\n",
    "    structure: List[str] = Field(\n",
    "        description=(\n",
    "            \"The folder structure or file organization for saving project files.\\n\"\n",
    "            \"Don't use the line-based representation of the folder structure (without the tree-like symbols like │, ├──, and └──)\\n\"\n",
    "            \"Example:\\n\"\n",
    "            \"project-name/ \"\n",
    "            \"project-name/src/\\n\"\n",
    "            \"project-name/src/main.py\\n\"\n",
    "            \"project-name/src/utils/\\n\"\n",
    "            \"project-name/src/utils/helpers.py\\n\"\n",
    "            \"project-name/tests/\\n\"\n",
    "            \"project-name/tests/test_main.py\\n\"\n",
    "            \"project-name/README.md\\n\"\n",
    "            \"project-name/requirements.txt\\n\"\n",
    "            \"project-name/.gitignore\\n\"\n",
    "            \"follow the above example format don't try to use other format.\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENT_GENERATION_TEMPLATE = \"\"\"\n",
    "help me write the structure of file for any python project given - {project}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see an example segment\n",
    "from llm_imp import llm\n",
    "segment = llm.structured_predict(\n",
    "    StackInfo,\n",
    "    PromptTemplate(SEGMENT_GENERATION_TEMPLATE),\n",
    "    project=\"calculator\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackInfo(structure=['calculator/', 'calculator/src/', 'calculator/src/calculator.py', 'calculator/src/utils/', 'calculator/src/utils/operations.py', 'calculator/tests/', 'calculator/tests/test_calculator.py', 'calculator/README.md', 'calculator/requirements.txt', 'calculator/.gitignore'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=llm.complete(\"hi is there anyone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, I am here.  How can I help you?\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\aise hi\\-\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from flow import CodeMate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = CodeMate(timeout=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Understanding your goals\n",
      "--------Goals--------\n",
      "The user wants to learn how to build an AI code generation tool using the OpenAI API.  Given the phrasing, it's likely the user is a **beginner**.\n",
      "\n",
      "Summary (Beginner-friendly):\n",
      "\n",
      "The user wants to learn how to create a program that can write code automatically, using a special tool called the OpenAI API.  They need help understanding how to use this API to build their program.\n",
      "\n",
      "--------\n",
      "Generating General Stack information\n",
      "------Requirements--------\n",
      "OpenAI API key, Python programming knowledge, a code editor\n",
      "--------------------------\n",
      "--------Structure---------\n",
      "['project-name', 'project-name/src', 'project-name/src/main.py']\n",
      "--------------------------\n",
      "--------Tech Stack--------\n",
      "Python, OpenAI API\n",
      "--------------------------\n",
      "*****\n",
      "Working on these each files\n",
      "File: project-name/src/main.py\n",
      "-----file path------\n",
      "project-name/src/main.py\n",
      "--------------------\n",
      "---------code-------\n",
      "import openai\\n\\n# Set your OpenAI API key.  **REPLACE \\\"YOUR_API_KEY\\\" WITH YOUR ACTUAL KEY.**\\nopenai.api_key = \\\"YOUR_API_KEY\\\"\\n\\ndef generate_code(prompt):\\n    \\\"\\\"\\\"Generates code using the OpenAI API.\\\"\\\"\\\"\n",
      "    response = openai.Completion.create(\\n        engine=\\\"code-davinci-002\\\",  # Or a similar code generation engine\\n        prompt=prompt,\\n        max_tokens=150,  # Adjust as needed\\n        n=1,\\n        stop=None,\\n        temperature=0.7, # Adjust for creativity (0.0 - deterministic, 1.0 - very creative)\\n    )\\n    code = response.choices[0].text.strip()\\n    return code\\n\\nif __name__ == \\\"__main__\\\":\\n    user_prompt = input(\\\"Enter your code generation prompt: \\\" )\\n    generated_code = generate_code(user_prompt)\\n    print(\\\"\\nGenerated Code:\\n\\\")\\n    print(generated_code)\n",
      "--------------------\n",
      "-----file path------\n",
      "project-name/src/main.py\n",
      "Query regarding this file - i want streamlit chat interface also in main.py\n",
      "---------------------\n",
      "-----file path------\n",
      "project-name/src/main.py\n",
      "--------------------\n",
      "---------code-------\n",
      "import openai\n",
      "import streamlit as st\n",
      "\n",
      "# Set your OpenAI API key.  **REPLACE \\\"YOUR_API_KEY\\\" WITH YOUR ACTUAL KEY.**\n",
      "openai.api_key = \\\"YOUR_API_KEY\\\"\n",
      "\n",
      "def generate_code(prompt):\n",
      "    \\\"\\\"\\\"Generates code using the OpenAI API.\\\"\\\"\\\"\n",
      "    response = openai.Completion.create(\n",
      "        engine=\\\"code-davinci-002\\\",  # Or a similar code generation engine\n",
      "        prompt=prompt,\n",
      "        max_tokens=150,  # Adjust as needed\n",
      "        n=1,\n",
      "        stop=None,\n",
      "        temperature=0.7, # Adjust for creativity (0.0 - deterministic, 1.0 - very creative)\n",
      "    )\n",
      "    code = response.choices[0].text.strip()\n",
      "    return code\n",
      "\n",
      "st.title(\\\"AI Code Generation Tool\\\")\n",
      "\n",
      "if 'messages' not in st.session_state:\n",
      "    st.session_state.messages = []\n",
      "\n",
      "for message in st.session_state.messages:\n",
      "    with st.chat_message(message[\\\"role\\\"]) :\n",
      "        st.markdown(message[\\\"content\\\"] )\n",
      "\n",
      "if prompt := st.chat_input(\\\"Enter your code generation prompt:\\\"):\n",
      "    st.session_state.messages.append({\\\"role\\\": \\\"user\\\", \\\"content\\\": prompt})\n",
      "    with st.chat_message(\\\"user\\\") :\n",
      "        st.markdown(prompt)\n",
      "\n",
      "    with st.chat_message(\\\"assistant\\\") :\n",
      "        message_placeholder = st.empty()\n",
      "        full_response = \\\"\\\"\n",
      "        for chunk in generate_code(prompt).split('\\n'):\n",
      "            full_response += chunk + '\\n'\n",
      "            message_placeholder.markdown(full_response)\n",
      "        st.session_state.messages.append({\\\"role\\\": \\\"assistant\\\", \\\"content\\\": full_response})\n",
      "\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "result = await w.run(input=\"help me to ai coder using opean ai api\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hurray Project is completed!!!\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'>\n",
      "<class 'llama_index.core.workflow.events.StopEvent'>\n",
      "<class 'flow.RetryCode'>\n",
      "<class 'flow.ObjectiveClear'>\n",
      "<class 'flow.RetryGoals'>\n",
      "<class 'flow.RetryStack'>\n",
      "<class 'flow.Questionare'>\n",
      "codeMate.html\n"
     ]
    }
   ],
   "source": [
    "# Draw all\n",
    "from llama_index.utils.workflow import (\n",
    "    draw_all_possible_flows,\n",
    "    draw_most_recent_execution,\n",
    ")\n",
    "draw_all_possible_flows(CodeMate, filename=\"codeMate.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: project-name\n",
      "File: │\n",
      "Directory: ├── src\n",
      "File: main.py\n",
      "Directory: │   └── utils\n",
      "File: helpers.py\n",
      "File: │\n",
      "Directory: ├── tests\n",
      "File: test_main.py\n",
      "File: │\n",
      "File: README.md\n",
      "File: requirements.txt\n",
      "File: .gitignore\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def print_paths_from_structure(structure):\n",
    "    \"\"\"\n",
    "    Parses a string representation of a folder structure and prints the exact paths.\n",
    "    Handles general folder structures with nested directories and files.\n",
    "    \"\"\"\n",
    "    # Split the structure into lines\n",
    "    lines = structure.strip().split(\"\\n\")\n",
    "    \n",
    "    # Stack to track the current directory level\n",
    "    stack = [Path(\".\")]\n",
    "    \n",
    "    for line in lines:\n",
    "        # Remove leading/trailing whitespace\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  # Skip empty lines\n",
    "        \n",
    "        # Calculate the indentation level\n",
    "        indentation = len(line) - len(line.lstrip())\n",
    "        \n",
    "        # Update the stack based on the indentation level\n",
    "        while len(stack) > indentation // 4 + 1:\n",
    "            stack.pop()\n",
    "        \n",
    "        # Get the current directory\n",
    "        current_path = stack[-1]\n",
    "        \n",
    "        # Check if it's a directory or file\n",
    "        if line.endswith(\"/\"):\n",
    "            # It's a directory\n",
    "            dir_name = line.strip().rstrip(\"/\")\n",
    "            dir_path = current_path / dir_name\n",
    "            print(f\"Directory: {dir_path}\")\n",
    "            stack.append(dir_path)  # Move into the directory\n",
    "        elif \"└──\" in line or \"├──\" in line:\n",
    "            # It's a file (indicated by └── or ├──)\n",
    "            file_name = line.split(\"── \")[-1].strip()\n",
    "            file_path = current_path / file_name\n",
    "            print(f\"File: {file_path}\")\n",
    "        else:\n",
    "            # It's a root-level file or directory\n",
    "            if line.endswith(\"/\"):\n",
    "                dir_name = line.strip().rstrip(\"/\")\n",
    "                dir_path = current_path / dir_name\n",
    "                print(f\"Directory: {dir_path}\")\n",
    "                stack.append(dir_path)\n",
    "            else:\n",
    "                file_path = current_path / line.strip()\n",
    "                print(f\"File: {file_path}\")\n",
    "\n",
    "# Example usage\n",
    "structure = \"\"\"\n",
    "project-name/\n",
    "│\n",
    "├── src/\n",
    "│   ├── main.py\n",
    "│   └── utils/\n",
    "│       └── helpers.py\n",
    "│\n",
    "├── tests/\n",
    "│   └── test_main.py\n",
    "│\n",
    "├── README.md\n",
    "├── requirements.txt\n",
    "└── .gitignore\n",
    "\"\"\"\n",
    "\n",
    "print_paths_from_structure(structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: project-name/\n",
      "Directory: project-name/src/\n",
      "File: project-name/src/main.py\n",
      "Directory: project-name/src/utils/\n",
      "File: project-name/src/utils/helpers.py\n",
      "Directory: project-name/tests/\n",
      "File: project-name/tests/test_main.py\n",
      "File: project-name/README.md\n",
      "File: project-name/requirements.txt\n",
      "File: project-name/.gitignore\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def print_paths_from_simple_structure(structure):\n",
    "    \"\"\"\n",
    "    Parses a simplified line-based folder structure and prints the exact paths.\n",
    "    \"\"\"\n",
    "    # Split the structure into lines\n",
    "    lines = structure.strip().split(\"\\n\")\n",
    "    \n",
    "    for line in lines:\n",
    "        # Remove leading/trailing whitespace\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  # Skip empty lines\n",
    "        \n",
    "        # Check if it's a directory or file\n",
    "        if line.endswith(\"/\"):\n",
    "            # It's a directory\n",
    "            print(f\"Directory: {line}\")\n",
    "        else:\n",
    "            # It's a file\n",
    "            print(f\"File: {line}\")\n",
    "\n",
    "# Example usage\n",
    "structure = \"\"\"\n",
    "project-name/\n",
    "project-name/src/\n",
    "project-name/src/main.py\n",
    "project-name/src/utils/\n",
    "project-name/src/utils/helpers.py\n",
    "project-name/tests/\n",
    "project-name/tests/test_main.py\n",
    "project-name/README.md\n",
    "project-name/requirements.txt\n",
    "project-name/.gitignore\n",
    "\"\"\"\n",
    "\n",
    "print_paths_from_simple_structure(structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: calculator_app/\n",
      "File: calculator_app/calculator.py\n",
      "File: calculator_app/README.md\n"
     ]
    }
   ],
   "source": [
    "print_paths_from_simple_structure(\"calculator_app/\\ncalculator_app/calculator.py\\ncalculator_app/README.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
